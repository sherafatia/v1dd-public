{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "operator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader, ConcatDataset\n",
      "File \u001b[0;32m~/anaconda3/envs/v1dd-public-2/lib/python3.10/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/v1dd-public-2/lib/python3.10/site-packages/torchvision/_meta_registrations.py:164\u001b[0m\n\u001b[1;32m    153\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(\n\u001b[1;32m    154\u001b[0m         grad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m rois\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m         ),\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[1;32m    163\u001b[0m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_custom_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl_abstract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchvision::nms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_nms\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should be a 2d tensor, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should have 4 elements in dimension 1, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/v1dd-public-2/lib/python3.10/site-packages/torch/library.py:1069\u001b[0m, in \u001b[0;36mregister_fake.<locals>.register\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1068\u001b[0m     use_lib \u001b[38;5;241m=\u001b[39m lib\n\u001b[0;32m-> 1069\u001b[0m \u001b[43muse_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_override\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/anaconda3/envs/v1dd-public-2/lib/python3.10/site-packages/torch/library.py:219\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[0;34m(self, op_name, fn, _stacklevel, allow_override)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m--> 219\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_to_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_override\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[0;32m~/anaconda3/envs/v1dd-public-2/lib/python3.10/site-packages/torch/_library/fake_impl.py:50\u001b[0m, in \u001b[0;36mFakeImplHolder.register\u001b[0;34m(self, func, source, lib, allow_override)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_has_kernel_for_dispatch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqualname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_has_kernel_for_dispatch_key(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompositeImplicitAutograd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m ):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import numpy as np\n",
    "from skimage.filters import gabor_kernel\n",
    "import copy\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FINAL, IMPROVED MODEL DEFINITION WITH CONCATENATION + SEPARATE HEADS ---\n",
    "class SkipConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SkipConvNet, self).__init__()\n",
    "        # Shared early layer\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Middle path for high-level features (will be noisy)\n",
    "        self.middle_layers = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Skip path for low-level features (will stay clean)\n",
    "        self.match_channels = nn.Conv2d(16, 32, kernel_size=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # --- Task-Specific Heads ---\n",
    "        # Both heads now take the full concatenated feature vector as input\n",
    "        # Input size is (32 channels from middle + 32 from skip) * 16 * 16\n",
    "        fc_input_size = 64 * 16 * 16\n",
    "        \n",
    "        # Head for CIFAR-10 (high-level task)\n",
    "        self.cifar_fc1 = nn.Linear(fc_input_size, 128)\n",
    "        self.cifar_fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        # Head for Gabor Orientation (low-level task)\n",
    "        self.gabor_fc1 = nn.Linear(fc_input_size, 128)\n",
    "        self.gabor_fc2 = nn.Linear(128, 12) # 12 orientation classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_conv1 = self.relu(self.conv1(x))\n",
    "        \n",
    "        # Process middle and skip paths\n",
    "        out_middle = self.relu(self.middle_layers(out_conv1))\n",
    "        skip_out = self.match_channels(out_conv1)\n",
    "\n",
    "        # Concatenate the clean and (potentially noisy) paths\n",
    "        out_combined = torch.cat((out_middle, skip_out), 1)\n",
    "\n",
    "        # Pool the combined feature map\n",
    "        pooled_combined = self.pool(out_combined)\n",
    "\n",
    "        # Flatten the result for the fully-connected layers\n",
    "        flat_combined = pooled_combined.view(-1, 64 * 16 * 16)\n",
    "        \n",
    "        # Process through separate, dedicated heads using the same combined input\n",
    "        cifar_out = self.cifar_fc2(self.relu(self.cifar_fc1(flat_combined)))\n",
    "        gabor_out = self.gabor_fc2(self.relu(self.gabor_fc1(flat_combined)))\n",
    "\n",
    "        # Return both outputs\n",
    "        return cifar_out, gabor_out\n",
    "\n",
    "# --- Noise injection function ---\n",
    "def add_noise_to_middle_layers(model, noise_level=0.5):\n",
    "    \"\"\"Injects Gaussian noise ONLY into the middle_layers path.\"\"\"\n",
    "    print(f\"Injecting noise with level: {noise_level:.2f}\")\n",
    "    with torch.no_grad():\n",
    "        for layer in model.middle_layers:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                noise = torch.randn_like(layer.weight.data) * noise_level\n",
    "                layer.weight.data += noise\n",
    "    return model\n",
    "\n",
    "# --- 1. Gabor Filter Dataset Generation ---\n",
    "class GaborDataset(Dataset):\n",
    "    def __init__(self, num_samples=10000, img_size=32, orientations=12, frequencies=(0.04, 0.08)):\n",
    "        self.num_samples = num_samples\n",
    "        self.img_size = img_size\n",
    "        self.orientations = np.linspace(0, np.pi, orientations, endpoint=False)\n",
    "        self.frequencies = frequencies\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        orientation_idx = np.random.randint(0, len(self.orientations))\n",
    "        theta = self.orientations[orientation_idx]\n",
    "        freq = np.random.choice(self.frequencies)\n",
    "        kernel = gabor_kernel(frequency=freq, theta=theta, sigma_x=15, sigma_y=15)\n",
    "        gabor_img_real = (kernel.real - np.min(kernel.real)) / (np.max(kernel.real) - np.min(kernel.real)) * 255\n",
    "        gabor_img_real = gabor_img_real.astype(np.uint8)\n",
    "        gabor_img_rgb = np.stack([gabor_img_real] * 3, axis=-1)\n",
    "        gabor_img_pil = Image.fromarray(gabor_img_rgb)\n",
    "        if self.transform:\n",
    "            gabor_img_transformed = self.transform(gabor_img_pil)\n",
    "        label = orientation_idx\n",
    "        return gabor_img_transformed, label\n",
    "\n",
    "# --- 2. Model and Finetuning Setup ---\n",
    "def finetune_model(model, combined_loader, num_epochs=5):\n",
    "    \"\"\"Finetunes the model on the combined CIFAR-10 and Gabor dataset.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    print(\"\\nStarting finetuning with separate heads...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(combined_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            cifar_outputs, gabor_outputs = model(inputs)\n",
    "            \n",
    "            # Identify data type by label range to calculate correct loss\n",
    "            is_cifar = labels < 10\n",
    "            is_gabor = labels >= 10\n",
    "            \n",
    "            loss = 0\n",
    "            # Calculate loss only for the relevant head and data\n",
    "            if is_cifar.any():\n",
    "                loss += criterion(cifar_outputs[is_cifar], labels[is_cifar])\n",
    "            \n",
    "            if is_gabor.any():\n",
    "                gabor_labels = labels[is_gabor] - 10 # Shift labels 10-21 -> 0-11\n",
    "                loss += criterion(gabor_outputs[is_gabor], gabor_labels)\n",
    "\n",
    "            if loss != 0:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() if isinstance(loss, torch.Tensor) else loss\n",
    "            if i % 100 == 99:\n",
    "                print(f'[Finetune Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "    print('Finished Finetuning')\n",
    "    return model\n",
    "\n",
    "# --- 3. Evaluation Functions for Multi-Task Model ---\n",
    "def evaluate_cifar_finetuned(model, testloader):\n",
    "    \"\"\"Evaluates the CIFAR-10 head.\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            cifar_outputs, _ = model(images) # Only use CIFAR output\n",
    "            _, predicted = torch.max(cifar_outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_gabor_finetuned(model, gabor_test_loader):\n",
    "    \"\"\"Evaluates the Gabor head.\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in gabor_test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, gabor_outputs = model(images) # Only use Gabor output\n",
    "            _, predicted = torch.max(gabor_outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# --- 4. Function to test robustness and plot results ---\n",
    "def test_and_plot_robustness(model, cifar_loader, gabor_loader, noise_levels):\n",
    "    \"\"\"\n",
    "    Evaluates model performance on both tasks across a range of noise levels\n",
    "    and plots the results.\n",
    "    \"\"\"\n",
    "    cifar_accuracies = []\n",
    "    gabor_accuracies = []\n",
    "\n",
    "    print(\"\\n--- Testing Robustness Across Noise Levels ---\")\n",
    "    for level in noise_levels:\n",
    "        noisy_model = copy.deepcopy(model)\n",
    "        noisy_model = add_noise_to_middle_layers(noisy_model, noise_level=level)\n",
    "        cifar_acc = evaluate_cifar_finetuned(noisy_model, cifar_loader)\n",
    "        gabor_acc = evaluate_gabor_finetuned(noisy_model, gabor_loader)\n",
    "        cifar_accuracies.append(cifar_acc)\n",
    "        gabor_accuracies.append(gabor_acc)\n",
    "\n",
    "    # Plotting absolute accuracies\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(noise_levels, cifar_accuracies, 'o-', label='CIFAR-10 Classification', color='blue')\n",
    "    plt.plot(noise_levels, gabor_accuracies, 's-', label='Gabor Orientation Classification', color='red')\n",
    "    plt.title('Model Performance vs. Noise Level')\n",
    "    plt.xlabel('Noise Level')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Plotting performance drop\n",
    "    pristine_cifar_acc = cifar_accuracies[0]\n",
    "    pristine_gabor_acc = gabor_accuracies[0]\n",
    "    cifar_drop = [pristine_cifar_acc - acc for acc in cifar_accuracies]\n",
    "    gabor_drop = [pristine_gabor_acc - acc for acc in gabor_accuracies]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(noise_levels, cifar_drop, 'o-', label='CIFAR-10 Drop', color='blue')\n",
    "    plt.plot(noise_levels, gabor_drop, 's-', label='Gabor Drop', color='red')\n",
    "    plt.title('Performance Drop vs. Noise Level')\n",
    "    plt.xlabel('Noise Level')\n",
    "    plt.ylabel('Accuracy Drop (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 5. Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    transform_cifar = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    cifar_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
    "    cifar_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
    "    cifar_test_loader = DataLoader(cifar_testset, batch_size=64, shuffle=False)\n",
    "\n",
    "    gabor_trainset = GaborDataset(num_samples=20000, orientations=12)\n",
    "    gabor_testset = GaborDataset(num_samples=5000, orientations=12)\n",
    "    gabor_test_loader = DataLoader(gabor_testset, batch_size=64, shuffle=False)\n",
    "\n",
    "    class GaborFinetuneDataset(Dataset):\n",
    "        def __init__(self, gabor_dataset):\n",
    "            self.gabor_dataset = gabor_dataset\n",
    "        def __len__(self):\n",
    "            return len(self.gabor_dataset)\n",
    "        def __getitem__(self, idx):\n",
    "            img, label = self.gabor_dataset[idx]\n",
    "            return img, label + 10 # Offset labels for combined training\n",
    "            \n",
    "    gabor_finetune_trainset = GaborFinetuneDataset(gabor_trainset)\n",
    "    combined_trainset = ConcatDataset([cifar_trainset, gabor_finetune_trainset])\n",
    "    combined_loader = DataLoader(combined_trainset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    model = SkipConvNet().to(device)\n",
    "    \n",
    "    FINETUNED_MODEL_PATH = './finetuned_multitask_model_concat_heads.pth'\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(FINETUNED_MODEL_PATH, map_location=device))\n",
    "        print(\"Loaded pre-trained finetuned model with concat + split heads.\")\n",
    "    except (FileNotFoundError, RuntimeError):\n",
    "        print(\"No compatible finetuned model found. Starting finetuning from scratch...\")\n",
    "        model = finetune_model(model, combined_loader, num_epochs=5)\n",
    "        torch.save(model.state_dict(), FINETUNED_MODEL_PATH)\n",
    "\n",
    "    print(\"\\n--- Evaluating Pristine Finetuned Model ---\")\n",
    "    pristine_cifar_acc = evaluate_cifar_finetuned(model, cifar_test_loader)\n",
    "    pristine_gabor_acc = evaluate_gabor_finetuned(model, gabor_test_loader)\n",
    "    print(f\"Pristine Model - CIFAR-10 Accuracy: {pristine_cifar_acc:.2f}%\")\n",
    "    print(f\"Pristine Model - Gabor Orientation Accuracy: {pristine_gabor_acc:.2f}%\")\n",
    "    \n",
    "    noise_levels_to_test = np.linspace(0, 0.5, 11) \n",
    "    test_and_plot_robustness(model, cifar_test_loader, gabor_test_loader, noise_levels_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v1dd-public-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
